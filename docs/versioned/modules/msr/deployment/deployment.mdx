---
sidebar_position: 1
sidebar_label: Deployment
---

# Deployment

This document provides comprehensive guidance on deploying the MSR (Multi-Session Replay) module backend infrastructure in production environments. A successful deployment consists of the MSR backend server and supporting infrastructure for change data capture. The frontend interface is provided through the MSR modlet installed in web-base projects.

## Prerequisites

Before deploying MSR, ensure you have:

-   **Container Runtime**: Docker or Podman with compose support
-   **Module Dependencies**: Deployed instance of `iams` module for authentication
-   **Network Access**: Connectivity between MSR components and dependency services
-   **Storage**: Adequate disk space for TimescaleDB and Redpanda data retention
-   **Environment File**: Properly configured `.env` file with required variables

## Container Images

The MSR backend deployment uses the following container images:

| Component            | Image                                               | Purpose                             |
| -------------------- | --------------------------------------------------- | ----------------------------------- |
| **MSR App**          | `ghcr.io/mssfoobar/msr/msr-app:latest`              | Main backend server                 |
| **MSR Database**     | `ghcr.io/mssfoobar/msr/timescaledb:2.22.0-pg17-aoh` | TimescaleDB for session data        |
| **Redpanda**         | `docker.redpanda.com/redpandadata/redpanda:latest`  | Kafka-compatible streaming platform |
| **Redpanda Console** | `docker.redpanda.com/redpandadata/console:latest`   | Redpanda management interface       |
| **Kafka Connect**    | `ghcr.io/mssfoobar/debezium-connect:latest`         | CDC connectors with Debezium        |

As of @mssfoobar/msr/msr-app version `1.2.0`, timescaledb version `2.22.0` is required for multi-column SkipScan support.

:::note Frontend Interface
The MSR frontend interface is provided through the MSR modlet, which is installed into web-base projects using `npx cli install msr`. No separate frontend container deployment is required.
:::

:::tip
Use specific version tags instead of `latest` for production deployments to ensure consistency and easier rollbacks.
:::

## Deployment Steps

### 1. Deploy Infrastructure

Deploy the infrastructure components using the dev-containers setup:

```bash
# From dev-containers directory
docker compose --env-file .env -f msr/compose.yml -f compose.override.yml up -d
```

This deploys:

-   **Database**: TimescaleDB instance for time-series data storage
-   **Redpanda**: Kafka-compatible streaming platform
-   **Kafka Connect**: CDC pipeline with Debezium connectors

See the [Kafka Connect configuration guide](../configuration/kafka-connect.mdx) for detailed connector setup.

### 2. Deploy Application

Deploy the MSR backend application:

**Artifact**: `ghcr.io/mssfoobar/msr/msr-app:latest`

Ensure the application is configured with proper environment variables. See the [configuration section](../configuration/app-configuration.mdx) for required variables.

#### Initial Bootstrap

On first deployment, MSR automatically:

-   **Creates initial snapshots** from existing CDC events
-   **Starts the cleanup service** if `CLEANUP_SERVICE_ENABLED=true`
-   **Validates data availability** boundaries based on configuration

:::tip Development Environment
Set `CLEANUP_SERVICE_ENABLED=false` in development to prevent automatic data cleanup during testing.
:::

### 3. Frontend Integration

The MSR frontend is provided through a modlet that developers install into their web-base projects:

```bash
# Install MSR modlet into web-base project
npx cli install msr
```

Developers can then build custom replay interfaces using the provided components. See the [quickstart guide](../quickstart/quickstart.mdx) for implementation details.

## Architecture Overview

The MSR deployment follows a CDC (Change Data Capture) architecture:

-   **MSR Backend**: Handles session recording, storage, and replay API
-   **MSR Database**: TimescaleDB instance optimized for time-series data
-   **CDC Pipeline**: Debezium + Kafka Connect + Redpanda for real-time data capture
-   **Frontend**: Provided via modlet components in web-base projects
-   **Dependencies**: IAMs for authentication, source databases with CDC-enabled tables

For detailed architectural concepts, see the [MSR overview](../overview.mdx).

## Network and Security Considerations

### Port Requirements

| Service          | Port | Purpose               | Access   |
| ---------------- | ---- | --------------------- | -------- |
| MSR Backend      | 8080 | API and web server    | Internal |
| MSR Database     | 5432 | PostgreSQL connection | Internal |
| Kafka Connect    | 8083 | REST API              | Internal |
| Redpanda         | 9092 | Kafka protocol        | Internal |
| Redpanda Console | 8080 | Management UI         | Internal |

### Security Best Practices

-   **Database Credentials**: Use strong passwords and rotate regularly
-   **Network Isolation**: Deploy in private networks with controlled access
-   **TLS/SSL**: Enable encryption for inter-service communication
-   **IAMs Integration**: Leverage centralized authentication for access control
-   **Resource Limits**: Configure container resource constraints

## Monitoring and Maintenance

### Automated Maintenance

MSR includes automated maintenance processes:

-   **CDC Cleanup Service**: Runs on configurable schedule (default: daily at 3am)
-   **Snapshot Refresh**: Updates rotating materialized views with latest entity states
-   **Data Retention**: Automatically removes old CDC events based on `MAX_PLAYBACK_RANGE`

### Data Availability Configuration

Control historical data availability through:

-   **MAX_PLAYBACK_RANGE**: Days of historical data available (default: 7)
-   **MAX_ACTIVE_SESSIONS**: Maximum concurrent replay sessions (default: 5)
-   **EARLIEST_VALID_TIMESTAMP**: Optional hard limit for earliest replay timestamp
-   **DATA_RETENTION_CRON_EXPRESSION**: Schedule for cleanup operations (default: '0 3 \* \* \*')

### Scaling Considerations

-   **Database Performance**: Monitor TimescaleDB performance and consider read replicas
-   **Kafka Connect**: Scale connector tasks based on CDC volume
-   **Redpanda**: Adjust partition count and replication factor for throughput

## Development and Testing

### MSR Web Container (Internal Use Only)

The MSR module includes a containerized web interface (`ghcr.io/mssfoobar/msr/msr-web:latest`) that is used exclusively for internal testing and modlet development purposes. This container:

-   **Is NOT deployed in production environments**
-   **Is NOT used by project developers**
-   Serves only as a testing artifact for modlet development
-   Provides a standalone interface for validating backend functionality

Project developers should use the MSR modlet installed via `npx cli install msr` instead of this container.

## Manual Snapshot Triggering

Sometimes, project engineers may need to manually trigger snapshots for their deployment outside of the normal CDC flow. The simplest way to do this with the expected MSR setup is to use Debezium's "ad-hoc snapshot" feature.

### Prerequisites

Ensure that all existing Kafka Connect Debezium Source connectors that need to be snapshotted have the following properties configured:

```json
{
  "...other existing properties...": "...",
  "signal.enabled.channels": "kafka",
  "signal.kafka.topic": "msr.debezium_adhoc_snapshots",
  "signal.kafka.bootstrap.servers": "redpanda:9092"
}
```

:::note Signal Topic Configuration
The signal topic name (`msr.debezium_adhoc_snapshots`) and bootstrap servers should match your Redpanda/Kafka configuration. Adjust these values according to your environment setup.
:::

### Triggering a Blocking Snapshot

To trigger a blocking ad-hoc snapshot, produce a message to the configured signal topic. The message must include both a **key** and a **value**:

**Message Key:** The value of `database.server.name` from your Kafka Connect Source Connector configuration (e.g., `gis_server`)

**Message Value:** JSON payload in the following format:

```json
{
    "id": "snapshot-1",
    "type": "execute-snapshot",
    "data": {
        "data-collections": [
            "gis.bookmark",
            "gis.geo_entity"
        ],
        "type": "blocking"
    }
}
```

**Message Parameters:**

- **Message Key**: Must match the `database.server.name` from the source connector configuration
- **`id`**: Must be unique for each snapshot request (e.g., `snapshot-1`, `snapshot-2024-01-15`, etc.)
- **`type`**: Must be set to `"execute-snapshot"` for snapshot operations
- **`data.data-collections`**: Array of table names that need to be snapshotted in `schema.table` format
- **`data.type`**: Must be set to `"blocking"` (incremental snapshots require additional setup and are not recommended)

### Sending the Signal

You can send the snapshot signal using any Kafka producer. For example, using Redpanda's rpk tool:

```bash
# Example using rpk to send snapshot signal
# Replace "gis_server" with your actual database.server.name value
echo '{
    "id": "snapshot-manual-2024-01-15",
    "type": "execute-snapshot",
    "data": {
        "data-collections": [
            "gis.bookmark",
            "gis.geo_entity"
        ],
        "type": "blocking"
    }
}' | rpk topic produce msr.debezium_adhoc_snapshots --key="gis_server"
```

:::important Message Key Requirement
The message key must exactly match the `database.server.name` value from your source connector configuration. If the connector was configured with `"database.server.name": "gis_server"`, then the message key must be `gis_server`.
:::

### Expected Behavior

When the signal is sent, the Debezium connector will:

1. **Trigger an ad-hoc snapshot** of the specified tables
2. **Generate "r" (read) operations** for all existing records in the specified tables
3. **Record these as CDC events** in the MSR `cdc_event` table
4. **Continue normal CDC processing** after the snapshot completes

:::warning Blocking Operations
Blocking snapshots may temporarily impact source database performance during execution. Plan accordingly and consider running during maintenance windows for large tables.
:::

:::tip Monitoring Progress
Monitor the Kafka Connect logs and the Redpanda Console to track snapshot progress and verify that CDC events are being generated as expected.
:::

## Troubleshooting

For common deployment issues, see the [FAQ section](../reference/faq.mdx) which covers:

-   CDC pipeline problems
-   Connector configuration issues
-   Database connection problems
-   Performance optimization
